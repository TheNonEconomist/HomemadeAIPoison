# HomemadeAIPoison
It's home-made and hurts bad AI... 

## What for? 
Hey your friend is just showing off some AI bot they made. And you really wanna rub it in their face. So you decide to poison their AI and teach them a lesson... ğŸ”ª ğŸ”ª ğŸ”ª 

I mean HELP them LEARN better AI Security and safety practices so they can DEPLOY safer and more robust AI. ğŸ˜Š ğŸ˜› ğŸ¤ª

## Problem:
Most AI poison pill tools don't publicize their code. Sure you can randomize your data or add adversarial examples or whatever but what if you're just some person who don't really know how AI works?
w
## Ok What is this really?
Telegram game where ppl can deploy their own models and others can poison pill it. 

Or an NFT project for super secretive group of whales. Who knows

Could be both or neither. Who knows.

## How Do:
Reverse Engineer some AI poison pills. 

Prepare some lab rats... ğŸğŸğŸ I mean AI models to poison...

Deploy on Telegram... OR Launch NFT? You'll never know

## Tools?
Good old-fashioned reverse engineering skills.

Some refreshers on how back-propagation and neural net activations work mathematically and functionally.

Off-the-shelf AI models as virtual lab rats...


## Disclaimer:
If this is successful, please do not use this for unethical or illegal purposes. I will find it out and make sure to report it to the authorities.

I want people to use this to defend against unethical and predatory uses of AI, not as an excuse to build malicious things. 

Welp tbh, you have some statistical guarantees that having some poisoned data won't completely ruin your AI model so there's that.

Also most AI API already come with their own security solutions so you can't inject shit. Otherwise it's a cybersecurity issue trynna intercept model weights or interfere with signal transfer from one place to another for transfer learning.
